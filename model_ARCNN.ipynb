{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Conv2DTranspose, SeparableConv2D\n",
    "from dataset import create_artifact_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'from tensorflow.keras.backend import set_session\\nimport tensorflow as tf\\nconfig = tf.ConfigProto()\\nconfig.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\\nconfig.log_device_placement = True  # to log device placement (on which device the operation ran)\\nsess = tf.Session(config=config)\\nset_session(sess)'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\"\"\"from tensorflow.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARCNN(input_shape=(32,32,1)):\n",
    "    inp = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(64,9,activation='relu', padding='same', use_bias=True,name=\"Feature_extract\")(inp)\n",
    "    conv2 = Conv2D(32,7,activation='relu', padding='same', use_bias=True,name=\"Feature_Enhance\")(conv1)\n",
    "    conv3 = Conv2D(64,1,activation='relu', padding='valid', use_bias=True,name=\"Mapping\")(conv2)\n",
    "    conv_trans = Conv2DTranspose(1,7,padding='same')(conv3)\n",
    "    ARCNN = Model(inputs=inp,outputs=conv_trans,name=\"ARCNN\")\n",
    "    return ARCNN\n",
    "\n",
    "def get_Fast_ARCNN(input_shape=(32,32,1)):\n",
    "    inp = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(64,9,activation='relu', padding='same', use_bias=True,name=\"Feature_extract\")(inp)\n",
    "    conv2 = Conv2D(32,1,activation='relu', padding='valid', use_bias=True,name=\"Feature_Enhance_speed\")(conv1)\n",
    "    conv3 = Conv2D(32,7,activation='relu', padding='same', use_bias=True,name=\"Feature_Enhance\")(conv2)\n",
    "    conv4 = Conv2D(64,1,activation='relu', padding='valid', use_bias=True,name=\"Mapping\")(conv3)\n",
    "    conv_trans = Conv2DTranspose(1,7,padding='same')(conv4)\n",
    "    ARCNN = Model(inputs=inp,outputs=conv_trans,name=\"Faster_ARCNN\")\n",
    "    return ARCNN\n",
    "\n",
    "def get_ARCNN_lite(input_shape=(32,32,1)):\n",
    "    inp = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32,5,dilation_rate=4,activation='relu', padding='same', use_bias=True,name=\"Feature_extract\")(inp)\n",
    "    conv2 = Conv2D(32,1,activation='relu', padding='valid', use_bias=True,name=\"Feature_Enhance_speed\")(conv1)\n",
    "    conv3 = Conv2D(32,5,dilation_rate=2,activation='relu', padding='same', use_bias=True,name=\"Feature_Enhance\")(conv2)\n",
    "    conv4 = Conv2D(32,1,activation='relu', padding='valid', use_bias=True,name=\"Mapping\")(conv3)\n",
    "    conv_trans = Conv2DTranspose(1,3,dilation_rate=4,name=\"Upscale\",padding='same')(conv4)\n",
    "    ARCNN = Model(inputs=inp,outputs=conv_trans)\n",
    "    return ARCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"ARCNN\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n_________________________________________________________________\nFeature_extract (Conv2D)     (None, 32, 32, 64)        5248      \n_________________________________________________________________\nFeature_Enhance (Conv2D)     (None, 32, 32, 32)        100384    \n_________________________________________________________________\nMapping (Conv2D)             (None, 32, 32, 64)        2112      \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 32, 32, 1)         3137      \n=================================================================\nTotal params: 110,881\nTrainable params: 110,881\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ARCNN = get_ARCNN()\n",
    "ARCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Faster_ARCNN\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n_________________________________________________________________\nFeature_extract (Conv2D)     (None, 32, 32, 64)        5248      \n_________________________________________________________________\nFeature_Enhance_speed (Conv2 (None, 32, 32, 32)        2080      \n_________________________________________________________________\nFeature_Enhance (Conv2D)     (None, 32, 32, 32)        50208     \n_________________________________________________________________\nMapping (Conv2D)             (None, 32, 32, 64)        2112      \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 32, 32, 1)         3137      \n=================================================================\nTotal params: 62,785\nTrainable params: 62,785\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Faster_ARCNN = get_Fast_ARCNN()\n",
    "Faster_ARCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 32, 32, 1)]       0         \n_________________________________________________________________\nFeature_extract (Conv2D)     (None, 32, 32, 32)        832       \n_________________________________________________________________\nFeature_Enhance_speed (Conv2 (None, 32, 32, 32)        1056      \n_________________________________________________________________\nFeature_Enhance (Conv2D)     (None, 32, 32, 32)        25632     \n_________________________________________________________________\nMapping (Conv2D)             (None, 32, 32, 32)        1056      \n_________________________________________________________________\nUpscale (Conv2DTranspose)    (None, 32, 32, 1)         289       \n=================================================================\nTotal params: 28,865\nTrainable params: 28,865\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ARCNN_lite = get_ARCNN_lite()\n",
    "ARCNN_lite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flist: 823\n",
      "Shapes\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "y_patches : (None, 100, 100, 1)\n",
      "x_patches : (None, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "data = create_artifact_dataset()\n",
    "data = data.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf346bbad0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mARCNN_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mssim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "ARCNN_v1.compile(optimizer=optimizer,loss=tf.keras.losses.MeanSquaredError(),metrics=[ssim,psnr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/no_batch\",write_images=True)\n",
    "es = tf.keras.callbacks.EarlyStoppinag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   3292/Unknown - 115s 35ms/step - loss: 0.0022 - ssim: 0.8762 - psnr: 30.9640WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,ssim,psnr\n",
      "3292/3292 [==============================] - 115s 35ms/step - loss: 0.0022 - ssim: 0.8762 - psnr: 30.9640\n",
      "Epoch 2/2\n",
      "3291/3292 [============================>.] - ETA: 0s - loss: 0.0014 - ssim: 0.8851 - psnr: 31.7328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,ssim,psnr\n",
      "3292/3292 [==============================] - 116s 35ms/step - loss: 0.0014 - ssim: 0.8851 - psnr: 31.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f020827c198>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARCNN_v1.fit(data,\n",
    "             epochs=2,\n",
    "             callbacks=[tboard,es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}